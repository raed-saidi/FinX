# Exported ML Data - Ready for Training

## Pipeline Run Summary
- **Created**: 2025-12-02 15:01:22.267707
- **Train Period**: Up to 2017-12-29
- **Validation Period**: 2017-12-29 to 2020-12-31 (for walk-forward hyperparameter tuning)
- **Test Period**: After 2020-12-31
- **Assets**: SPY, QQQ, EFA, IEF, HYG, BIL
- **Total Features**: 375
- **Train Samples**: 1706
- **Validation Samples**: 756
- **Test Samples**: 1004

## Three-Way Split Strategy

This dataset implements a **walk-forward validation** approach:

1. **Train Set** (2017-12-29 and earlier): Used for initial model training
2. **Validation Set** (2017-12-29 to 2020-12-31): Used for hyperparameter tuning and model selection
3. **Test Set** (After 2020-12-31): Held-out data for final performance evaluation

**Important**: The test set should NEVER be used during model development or tuning. Use train + validation for all experimentation.

## Directory Structure

```
exported_data/
├── per_asset/           # Per-asset model training data
│   ├── SPY/
│   │   ├── X_train.parquet  (70 features)
│   │   ├── X_val.parquet
│   │   ├── X_test.parquet
│   │   ├── y_train.parquet  (SPY returns)
│   │   ├── y_val.parquet
│   │   ├── y_test.parquet
│   │   └── metadata.json
│   └── (... 5 more assets)
│
├── global/              # RL ensemble training data
│   ├── X_train.parquet  (375 features × 1706 samples)
│   ├── X_val.parquet
│   ├── X_test.parquet
│   ├── y_train.parquet  (6 targets)
│   ├── y_val.parquet
│   ├── y_test.parquet
│   ├── prices_train.parquet
│   ├── prices_val.parquet
│   └── prices_test.parquet
│
├── scalers/
│   └── global_scaler.joblib
│
├── manifest.json        # Complete metadata catalog
└── README.txt           # This file

```

## Quick Start - Training Per-Asset Models

```python
import pandas as pd
from pathlib import Path

# Load data for one asset (e.g., SPY)
ticker = "SPY"
data_dir = Path("data/exported_data/per_asset") / ticker

X_train = pd.read_parquet(data_dir / "X_train.parquet")
y_train = pd.read_parquet(data_dir / "y_train.parquet")
X_val = pd.read_parquet(data_dir / "X_val.parquet")
y_val = pd.read_parquet(data_dir / "y_val.parquet")
X_test = pd.read_parquet(data_dir / "X_test.parquet")
y_test = pd.read_parquet(data_dir / "y_test.parquet")

# Train model with validation-based early stopping
from lightgbm import LGBMRegressor
model = LGBMRegressor(n_estimators=1000, learning_rate=0.05)
model.fit(
    X_train, y_train[ticker],
    eval_set=[(X_val, y_val[ticker])],
    callbacks=[lgb.early_stopping(50)]
)

# Final evaluation on test set
predictions = model.predict(X_test)
```

## Quick Start - Training RL Ensemble

```python
# Load global dataset with all assets
X_train = pd.read_parquet("data/exported_data/global/X_train.parquet")
X_val = pd.read_parquet("data/exported_data/global/X_val.parquet")
y_train = pd.read_parquet("data/exported_data/global/y_train.parquet")
prices = pd.read_parquet("data/exported_data/global/prices_train.parquet")

# Your RL training code here
# State: X_train (features) + previous predictions from per-asset models
# Action: Portfolio weights
# Reward: Sharpe ratio from y_train and prices
```

## Data Quality Guarantees

✅ No missing values (NaN)
✅ All features scaled (mean≈0, std≈1)
✅ DatetimeIndex preserved
✅ Train/test temporal split (no look-ahead bias)
✅ Indices aligned between X and y

## Next Steps

1. Train 3 models per asset (LightGBM, XGBoost, LSTM) → See `scripts/train_per_asset_models.py`
2. Evaluate and select best model per asset
3. Use best models' predictions as input to RL ensemble
4. Backtest the full strategy with transaction costs

## Metadata

See `manifest.json` for complete pipeline metadata including:
- Feature names and counts per asset
- Train/test statistics
- Date ranges
- File paths

---
Generated by ZenML Data Pipeline v1.0
